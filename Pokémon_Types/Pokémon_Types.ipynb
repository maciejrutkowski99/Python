{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "1605bdf0-0e94-4d07-9512-5a9a89cae003",
      "cell_type": "code",
      "source": "from skimage import io\nimport PIL.Image\nimport numpy as np\nimport os",
      "metadata": {},
      "outputs": [],
      "execution_count": 42
    },
    {
      "id": "e437d6e5-8e12-409d-856b-adaa9e6b95f7",
      "cell_type": "code",
      "source": "#Feature Matrix\narray_of_samples = np.ones((1,43200))\ndirectory = os.fsencode('RGB_PNG')\nfor file in os.listdir(directory):\n    filename = os.fsdecode(file)\n    if filename.endswith(\".png\"):   #ignore files ending with .ipynb_checkpoints\n        img = io.imread('RGB_PNG/' + filename) #load image\n        four_dim_array = np.array(img)\n        one_dim_array = four_dim_array.reshape(1,43200) #convert into one long array\n        array_of_samples = np.vstack([array_of_samples, one_dim_array])\nprint(array_of_samples.shape)\narray_of_samples = array_of_samples[1:][:] #delete the first row of ones which was used only to initialize the array\nprint(array_of_samples.shape)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(722, 43200)\n,(721, 43200)\n"
        }
      ],
      "execution_count": 43
    },
    {
      "id": "03063b4f-b062-4918-82ce-4ee055a5ec7d",
      "cell_type": "code",
      "source": "#Labels\nimport pandas as pd\nmy_csv = pd.read_csv('pokemon.csv')\nmy_csv = my_csv[:721]\nmy_csv = my_csv.sort_values(by = 'Name')      \nlabels = np.array(my_csv.Type1)\n\n\n#Conversion of types(labels) to numbers\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nlabels = le.fit_transform(labels)\nlabels = np.expand_dims(labels, axis = 1) #conversion into a correct vector\nlabels.shape",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(721, 1)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 44
    },
    {
      "id": "abf2fb2d-d15f-43b3-bb15-e6b6bd97354d",
      "cell_type": "code",
      "source": "#Split into Training and Test sets\n\narray_of_samples /= 255\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(array_of_samples, labels, test_size=0.20, random_state=21, stratify = labels)\nx_train.shape, x_valid.shape, y_train.shape, y_valid.shape\n\ny_train = y_train.flatten()\ny_valid = y_valid.flatten()                  \n\nx_train.shape, x_valid.shape, y_train.shape, y_valid.shape",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((576, 43200), (145, 43200), (576,), (145,))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 45
    },
    {
      "id": "8d8bfb7c-ed7c-4fcd-91aa-7ef8907880db",
      "cell_type": "code",
      "source": "#Categorize Labels\nimport tensorflow.keras as keras\nnum_classes = 18               #18 pokemon types\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_valid = keras.utils.to_categorical(y_valid, num_classes)",
      "metadata": {},
      "outputs": [],
      "execution_count": 46
    },
    {
      "id": "1669ade9-e2af-48f5-b48d-4be29c5d576f",
      "cell_type": "code",
      "source": "#Build model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(units = 512, activation='relu', input_shape=(43200,)))\nmodel.add(Dense(units = 512, activation='relu'))\nmodel.add(Dense(units = num_classes, activation='softmax'))",
      "metadata": {},
      "outputs": [],
      "execution_count": 52
    },
    {
      "id": "8253a41b-7943-4afd-aabc-558cc01117ac",
      "cell_type": "code",
      "source": "model.summary()",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Model: \"sequential_5\"\n,_________________________________________________________________\n, Layer (type)                Output Shape              Param #   \n,=================================================================\n, dense_15 (Dense)            (None, 512)               22118912  \n,                                                                 \n, dense_16 (Dense)            (None, 512)               262656    \n,                                                                 \n, dense_17 (Dense)            (None, 18)                9234      \n,                                                                 \n,=================================================================\n,Total params: 22,390,802\n,Trainable params: 22,390,802\n,Non-trainable params: 0\n,_________________________________________________________________\n"
        }
      ],
      "execution_count": 53
    },
    {
      "id": "c6d70e27-9f14-4d9e-a945-f7768bedbf6c",
      "cell_type": "code",
      "source": "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])",
      "metadata": {},
      "outputs": [],
      "execution_count": 54
    },
    {
      "id": "e000e8ba-6cc3-4db0-9e57-b561fe97bcb3",
      "cell_type": "code",
      "source": "model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch 1/20\n,18/18 [==============================] - 6s 306ms/step - loss: 9.7596 - accuracy: 0.1059 - val_loss: 3.2137 - val_accuracy: 0.0966\n,Epoch 2/20\n,18/18 [==============================] - 5s 279ms/step - loss: 2.8399 - accuracy: 0.1424 - val_loss: 2.8822 - val_accuracy: 0.1103\n,Epoch 3/20\n,18/18 [==============================] - 5s 275ms/step - loss: 2.4896 - accuracy: 0.2378 - val_loss: 3.1588 - val_accuracy: 0.1517\n,Epoch 4/20\n,18/18 [==============================] - 5s 289ms/step - loss: 2.2674 - accuracy: 0.2934 - val_loss: 2.9017 - val_accuracy: 0.1448\n,Epoch 5/20\n,18/18 [==============================] - 5s 307ms/step - loss: 1.9943 - accuracy: 0.3837 - val_loss: 3.3223 - val_accuracy: 0.1655\n,Epoch 6/20\n,18/18 [==============================] - 7s 373ms/step - loss: 1.7491 - accuracy: 0.4514 - val_loss: 3.1231 - val_accuracy: 0.1655\n,Epoch 7/20\n,18/18 [==============================] - 8s 436ms/step - loss: 1.4820 - accuracy: 0.5278 - val_loss: 3.4283 - val_accuracy: 0.1586\n,Epoch 8/20\n,18/18 [==============================] - 7s 361ms/step - loss: 1.1648 - accuracy: 0.6736 - val_loss: 3.3595 - val_accuracy: 0.1241\n,Epoch 9/20\n,18/18 [==============================] - 7s 398ms/step - loss: 1.1325 - accuracy: 0.6753 - val_loss: 3.6814 - val_accuracy: 0.2000\n,Epoch 10/20\n,18/18 [==============================] - 6s 329ms/step - loss: 0.5827 - accuracy: 0.8194 - val_loss: 4.1271 - val_accuracy: 0.1793\n,Epoch 11/20\n,18/18 [==============================] - 5s 291ms/step - loss: 0.7930 - accuracy: 0.8003 - val_loss: 3.9110 - val_accuracy: 0.1862\n,Epoch 12/20\n,18/18 [==============================] - 5s 289ms/step - loss: 0.4498 - accuracy: 0.8663 - val_loss: 4.4526 - val_accuracy: 0.1724\n,Epoch 13/20\n,18/18 [==============================] - 5s 282ms/step - loss: 0.3023 - accuracy: 0.9149 - val_loss: 5.1856 - val_accuracy: 0.1724\n,Epoch 14/20\n,18/18 [==============================] - 6s 317ms/step - loss: 0.7486 - accuracy: 0.8455 - val_loss: 5.8959 - val_accuracy: 0.1379\n,Epoch 15/20\n,18/18 [==============================] - 5s 277ms/step - loss: 0.1266 - accuracy: 0.9670 - val_loss: 4.7599 - val_accuracy: 0.2000\n,Epoch 16/20\n,18/18 [==============================] - 5s 280ms/step - loss: 0.6191 - accuracy: 0.8681 - val_loss: 5.5993 - val_accuracy: 0.1379\n,Epoch 17/20\n,18/18 [==============================] - 6s 309ms/step - loss: 0.0538 - accuracy: 0.9931 - val_loss: 5.4653 - val_accuracy: 0.1793\n,Epoch 18/20\n,18/18 [==============================] - 8s 457ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 5.3830 - val_accuracy: 0.1931\n,Epoch 19/20\n,18/18 [==============================] - 7s 388ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.2214 - val_accuracy: 0.1310\n,Epoch 20/20\n,18/18 [==============================] - 6s 341ms/step - loss: 1.4478 - accuracy: 0.8212 - val_loss: 6.6062 - val_accuracy: 0.1448\n"
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ed260d8f40>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 55
    },
    {
      "id": "06895743-0df3-438f-b9a9-f73e10181876",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}